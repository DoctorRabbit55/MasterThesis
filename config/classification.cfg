[GENERAL]
logging level = 20
calc knowledge quotient = False
train original model = False
train shunt model = False
test shunt model = False
train final model = False
test fine-tune strategies = True
test latency = False

[DATASET]
name = CIFAR10

[MODEL]
type = MobileNetV2
from file = False
filepath = 
pretrained = True
weightspath = E:\Masterarbeit\MasterThesis\saved\MobilenetV2_91.81.h5
scale up input = False
change stride layers = 2

[TRAINING_ORIGINAL_MODEL]
batchsize = 64
epochs first cycle = 20
learning rate first cycle = 0.001
epochs second cycle = 1
learning rate second cycle = 0.001

[TRAINING_SHUNT_MODEL]
batchsize = 64
epochs first cycle = 40
learning rate first cycle = 0.1
epochs second cycle = 40
learning rate second cycle = 0.001

[TRAINING_FINAL_MODEL]
finetune strategy = unfreeze_after_shunt
# strategies: unfreeze_all, unfreeze_shunt, unfreeze_after_shunt, unfreeze_per_epoch_starting_top, unfreeze_per_epoch_starting_shunt = 
batchsize = 64
epochs first cycle = 30
learning rate first cycle = 0.1
epochs second cycle = 0
learning rate second cycle = 1e-05

[SHUNT]
location = 62,114
arch = 1
input shape = 8,8,64
output shape = 8,8,96
from file = False
filepath = 
pretrained = True
weightspath = E:\Masterarbeit\MasterThesis\log\20200810\22_21_17\shunt_model_weights.h5
featuremapspath = E:\Masterarbeit\MasterThesis\saved\feature_maps\CIFAR10\MobileNetV2_reduced

[FINAL_MODEL]
pretrained = False
weightspath = E:\Masterarbeit\MasterThesis\log\20200828\00_35_49\final_model_weights.h5

